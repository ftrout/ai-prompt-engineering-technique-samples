{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self-Consistency Prompting Example\n",
    "\n",
    "This notebook demonstrates **Self-Consistency**, a technique that improves accuracy on reasoning tasks by \"asking the audience\" (where the audience is the model itself).\n",
    "\n",
    "**The Concept:**\n",
    "LLMs are probabilistic. If you ask a complex question once, it might take a wrong turn in its reasoning.\n",
    "**Self-Consistency** mitigates this by:\n",
    "1.  **Sampling**: Asking the *same* question multiple times (e.g., 5 times).\n",
    "2.  **Reasoning**: Letting the model generate a full Chain of Thought for each attempt.\n",
    "3.  **Voting**: Comparing the final answers and selecting the one that appears most frequently.\n",
    "\n",
    "**Key Mechanics:**\n",
    "* **Diversity**: We use a non-zero temperature to ensure each reasoning path is slightly different.\n",
    "* **Consensus**: If 4 out of 5 reasoning paths lead to \"Answer: 42,\" we can be much more confident than if we only asked once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install openai python-dotenv --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Setup and Authorization\n",
    "\n",
    "We start by importing the necessary libraries and loading your OpenAI API key. We also import `Counter` from Python's standard library to help us tally the votes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from openai import OpenAI\nimport os\nfrom dotenv import load_dotenv\nfrom collections import Counter\n\nload_dotenv()\n\napi_key = os.getenv(\"OPENAI_API_KEY\")\nif not api_key:\n    api_key = input(\"Paste your OpenAI API key: \").strip()\n\nclient = OpenAI(api_key=api_key)\nprint(\"OpenAI client ready!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. The Self-Consistency Engine\n",
    "\n",
    "This function runs the core logic.\n",
    "\n",
    "**How it works:**\n",
    "1.  **Loop**: It runs a loop `num_samples` times (default is 5).\n",
    "2.  **Generate**: It calls the API for each sample.\n",
    "    * **Crucial Detail**: We set `temperature=0.7`. If we used 0, every answer would be identical, defeating the purpose. We need slight variations in the reasoning path to test robustness.\n",
    "3.  **Extract**: It parses the model's output to find the final answer (assuming the answer is on the last line).\n",
    "4.  **Vote**: It uses `Counter` to find the most common result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "SYSTEM_PROMPT = \"\"\"\nSolve using chain of thought: Break down step by step and give a final answer.\nEnsure your final answer is on the very last line of your response.\n\"\"\"\n\ndef get_self_consistent_answer(query, num_samples=5):\n    print(f\"Generating {num_samples} reasoning paths for: '{query}'...\\n\")\n    answers = []\n    \n    for i in range(num_samples):\n        try:\n            # 1. Generate a Reasoning Path\n            response = client.chat.completions.create(\n                model=\"gpt-4o-mini\",\n                messages=[\n                    {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n                    {\"role\": \"user\", \"content\": query}\n                ],\n                temperature=0.7  # Higher temp = diverse reasoning paths\n            )\n            \n            reply = response.choices[0].message.content.strip()\n            \n            # 2. Extract Final Answer (Simple heuristic: take the last line)\n            # In a real app, you might ask for a specific format like \"Answer: <X>\"\n            final_ans = reply.split(\"\\n\")[-1].strip()\n            answers.append(final_ans)\n            \n            print(f\"--- Path {i+1} ---\")\n            print(f\"Reasoning: {reply[:100]}...\") # Show snippet\n            print(f\"Result: {final_ans}\\n\")\n            \n        except Exception as e:\n            print(f\"Error on path {i+1}: {e}\")\n            continue\n\n    if not answers:\n        return None, 0, {}\n\n    # 3. Aggregation (Majority Voting)\n    print(\"-\" * 30)\n    vote_counts = Counter(answers)\n    most_common, count = vote_counts.most_common(1)[0]\n    \n    return most_common, count, vote_counts"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Run the Consistency Check\n",
    "\n",
    "Now we test it. This technique is particularly famous for solving math word problems or logic puzzles where there is a single correct answer, but many ways to get lost.\n",
    "\n",
    "**Try asking:**\n",
    "* \"If I have 3 apples, eat one, buy two more, and drop half of them, how many do I have?\"\n",
    "* \"Janet is older than Bob. Bob is younger than Tom. Tom is older than Janet. Is this possible?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = input(\"Enter a problem for self-consistency: \")\n",
    "\n",
    "if query:\n",
    "    winner, count, all_votes = get_self_consistent_answer(query, num_samples=5)\n",
    "    \n",
    "    print(f\"üèÜ MOST CONSISTENT ANSWER: {winner}\")\n",
    "    print(f\"Confidence: {count}/5 votes\")\n",
    "    print(f\"Vote Distribution: {dict(all_votes)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}