{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph of Thought (GoT) Prompting Example\n",
    "\n",
    "This notebook demonstrates **Graph of Thought (GoT)**, one of the most advanced reasoning frameworks for LLMs.\n",
    "\n",
    "**The Concept:**\n",
    "Standard \"Chain of Thought\" is linear (Step 1 → Step 2 → Step 3). **Graph of Thought** models reasoning as a network (DAG - Directed Acyclic Graph).\n",
    "* **Nodes**: Individual thoughts or intermediate steps.\n",
    "* **Edges**: Relationships (e.g., \"Step 1 *supports* Step 2\", \"Step 3 *contradicts* Step 1\").\n",
    "* **Transformations**: Thoughts can merge (aggregation), split (branching), or loop back (refinement).\n",
    "\n",
    "**Key Mechanics:**\n",
    "1.  **Prompting for Structure**: We force the LLM to output its reasoning as a **JSON** object containing `nodes` and `edges`.\n",
    "2.  **Parsing**: We read this structured output to understand the relationship between thoughts.\n",
    "3.  **Visualization**: We can potentially map or display this network to see how the model arrived at the answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install openai python-dotenv networkx matplotlib --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Setup and Authorization\n",
    "\n",
    "We import `openai` for the LLM, `json` for parsing the structured output, and `networkx` to manage the graph structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from openai import OpenAI\nimport os\nimport json\nimport re\nimport networkx as nx\nfrom dotenv import load_dotenv\n\nload_dotenv()\n\napi_key = os.getenv(\"OPENAI_API_KEY\")\nif not api_key:\n    api_key = input(\"Paste your OpenAI API key: \").strip()\n\n# Model configuration - can be overridden via environment variable\nMODEL = os.getenv(\"OPENAI_MODEL\", \"gpt-4o-mini\")\n\nclient = OpenAI(api_key=api_key)\nprint(f\"OpenAI client ready! Using model: {MODEL}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. The GoT Function (The \"Network Builder\")\n",
    "\n",
    "This function performs the heavy lifting:\n",
    "1.  **Prompting**: It sends a strict instruction to the model to output JSON only.\n",
    "2.  **Parsing**: It cleans the raw string (removing Markdown backticks) and converts it to a Python dictionary.\n",
    "3.  **Graph Construction**: It uses the `networkx` library to actually build the graph object in memory, adding nodes and connecting them with edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def clean_json_output(raw_content):\n    \"\"\"\n    Clean model output to extract valid JSON.\n    Handles common issues like markdown code blocks and extra text.\n    \"\"\"\n    content = raw_content.strip()\n    \n    # Remove markdown code blocks (```json ... ``` or ``` ... ```)\n    content = re.sub(r'^```(?:json)?\\s*\\n?', '', content)\n    content = re.sub(r'\\n?```\\s*$', '', content)\n    \n    # Try to find JSON object boundaries if there's extra text\n    json_match = re.search(r'\\{[\\s\\S]*\\}', content)\n    if json_match:\n        content = json_match.group(0)\n    \n    return content.strip()\n\ndef graph_of_thought(problem):\n    print(f\"Building reasoning graph for: '{problem}'...\\n\")\n    \n    try:\n        # 1. Generate the Graph (JSON)\n        response = client.chat.completions.create(\n            model=MODEL,\n            messages=[{\n                \"role\": \"user\", \n                \"content\": f\"\"\"\nSolve this using Graph-of-Thought reasoning.\nProblem: {problem}\n\nYou must output your reasoning structure as a valid JSON object.\nFormat:\n{{\n  \"nodes\": {{\n    \"1\": \"First thought or initial analysis\",\n    \"2\": \"Another perspective or calculation\",\n    \"3\": \"Merged insight from 1 and 2\",\n    \"4\": \"Final Conclusion\"\n  }},\n  \"edges\": [\n    [1, 3, \"supports\"],\n    [2, 3, \"combines_with\"],\n    [3, 4, \"leads_to\"]\n  ],\n  \"final_answer\": \"The concise answer here\"\n}}\n\nDo not add any markdown formatting or explanation outside the JSON.\n\"\"\"\n            }],\n            temperature=0.7 # Some creativity allowed for branching thoughts\n        )\n        \n        raw_content = response.choices[0].message.content.strip()\n\n        # 2. Parse JSON with robust cleaning\n        clean_json = clean_json_output(raw_content)\n        data = json.loads(clean_json)\n        \n        # 3. Build Graph Object\n        G = nx.DiGraph()\n        \n        # Add Nodes\n        print(\"Thoughts (Nodes):\")\n        for node_id, text in data[\"nodes\"].items():\n            G.add_node(node_id, label=text)\n            print(f\"  [{node_id}] {text}\")\n            \n        # Add Edges\n        print(\"\\nRelationships (Edges):\")\n        for source, target, relation in data[\"edges\"]:\n            G.add_edge(str(source), str(target), label=relation)\n            print(f\"  [{source}] --({relation})--> [{target}]\")\n            \n        print(\"\\n\" + \"=\"*50)\n        print(f\"FINAL ANSWER: {data['final_answer']}\")\n        print(\"=\"*50)\n        \n        return G, data\n\n    except json.JSONDecodeError as e:\n        print(f\"Error: The model failed to output valid JSON. {e}\")\n        print(\"Raw output:\\n\", raw_content if 'raw_content' in locals() else \"No response\")\n        return None, None\n    except Exception as e:\n        print(f\"Error: {e}\")\n        return None, None"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Running the Graph of Thought\n",
    "\n",
    "Now we test it. Try a complex problem that benefits from non-linear thinking, such as:\n",
    "* \"Write a story summary where the ending contradicts the beginning but makes sense.\"\n",
    "* \"Analyze the economic impact of AI, considering both job loss and productivity gains, and merge them.\"\n",
    "* \"Solve a riddle that requires combining two disparate clues.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_problem = input(\"Enter a complex problem: \")\n",
    "\n",
    "if user_problem:\n",
    "    graph, details = graph_of_thought(user_problem)\n",
    "    \n",
    "    if graph:\n",
    "        print(f\"\\nGraph successfully built with {graph.number_of_nodes()} nodes and {graph.number_of_edges()} edges.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}