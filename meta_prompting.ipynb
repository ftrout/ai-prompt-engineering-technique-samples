{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meta-Prompting Example\n",
    "\n",
    "This notebook demonstrates **Meta-Prompting**, an advanced technique where the AI helps design, refine, and optimize prompts.\n",
    "\n",
    "**The Concept:**\n",
    "Instead of manually crafting prompts, you describe your goal to the AI and let it generate an optimized prompt for you. This is particularly useful when:\n",
    "* You're unsure how to phrase a complex request\n",
    "* You want to explore different prompting strategies\n",
    "* You need to adapt prompts for specific use cases\n",
    "\n",
    "**Key Mechanics:**\n",
    "1. **Goal Description**: You describe what you want to achieve.\n",
    "2. **Prompt Generation**: The AI creates an optimized prompt based on best practices.\n",
    "3. **Iterative Refinement**: You can ask for variations or improvements.\n",
    "4. **Execution**: Use the generated prompt with your actual task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install openai python-dotenv --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Setup and Authorization\n",
    "\n",
    "We start by importing the necessary libraries and loading your OpenAI API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not api_key:\n",
    "    api_key = input(\"Paste your OpenAI API key: \").strip()\n",
    "\n",
    "client = OpenAI(api_key=api_key)\n",
    "print(\"OpenAI client ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. The Meta-Prompt (The \"Prompt Engineer\")\n",
    "\n",
    "This system prompt transforms the AI into a prompt engineering expert. It instructs the model to:\n",
    "* Understand the user's goal deeply\n",
    "* Apply prompt engineering best practices\n",
    "* Generate structured, effective prompts\n",
    "* Explain the reasoning behind design choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "META_PROMPT = \"\"\"\n",
    "You are an expert Prompt Engineer. Your task is to help users create highly effective prompts.\n",
    "\n",
    "When a user describes their goal, you will:\n",
    "\n",
    "1. **Analyze the Goal**: Identify the core task, desired output format, and any constraints.\n",
    "\n",
    "2. **Apply Best Practices**:\n",
    "   - Use clear, specific instructions\n",
    "   - Include relevant context and constraints\n",
    "   - Specify the desired output format\n",
    "   - Add examples if helpful (few-shot)\n",
    "   - Consider edge cases\n",
    "   - Use appropriate persona/role if beneficial\n",
    "\n",
    "3. **Generate the Prompt**: Create a complete, ready-to-use prompt wrapped in a code block.\n",
    "\n",
    "4. **Explain Your Choices**: Briefly explain why you structured the prompt this way.\n",
    "\n",
    "5. **Offer Variations**: Suggest 1-2 alternative approaches if relevant.\n",
    "\n",
    "Format your response as:\n",
    "## Generated Prompt\n",
    "```\n",
    "[The optimized prompt here]\n",
    "```\n",
    "\n",
    "## Why This Works\n",
    "[Brief explanation]\n",
    "\n",
    "## Alternative Approaches\n",
    "[Optional variations]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. The Meta-Prompting Engine\n",
    "\n",
    "This function takes your goal and generates an optimized prompt.\n",
    "\n",
    "**Why use `temperature=0.7`?**\n",
    "* We want some creativity in prompt design\n",
    "* But not so much that the output becomes inconsistent\n",
    "* This balance allows for innovative yet reliable prompt generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt(goal: str) -> str:\n",
    "    \"\"\"Generate an optimized prompt for the given goal.\"\"\"\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": META_PROMPT},\n",
    "                {\"role\": \"user\", \"content\": f\"Create an optimized prompt for this goal:\\n\\n{goal}\"}\n",
    "            ],\n",
    "            temperature=0.7\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n",
    "\n",
    "def refine_prompt(original_prompt: str, feedback: str) -> str:\n",
    "    \"\"\"Refine an existing prompt based on feedback.\"\"\"\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": META_PROMPT},\n",
    "                {\"role\": \"user\", \"content\": f\"\"\"Refine this prompt based on the feedback:\n",
    "\n",
    "Original Prompt:\n",
    "{original_prompt}\n",
    "\n",
    "Feedback:\n",
    "{feedback}\n",
    "\n",
    "Generate an improved version.\"\"\"}\n",
    "            ],\n",
    "            temperature=0.7\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Interactive Meta-Prompting Session\n",
    "\n",
    "Now we run the interactive session. Describe your goal and get an optimized prompt!\n",
    "\n",
    "**Try asking for:**\n",
    "* \"A prompt that summarizes legal documents for non-lawyers\"\n",
    "* \"A prompt for generating creative product names\"\n",
    "* \"A prompt that helps debug Python code step by step\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Meta-Prompting Engine Ready!\")\n",
    "print(\"Describe your goal and I'll generate an optimized prompt for you.\")\n",
    "print(\"Type 'refine' to improve the last prompt, or 'quit' to exit.\\n\")\n",
    "\n",
    "last_prompt = None\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"Your goal: \").strip()\n",
    "    \n",
    "    if user_input.lower() in [\"quit\", \"exit\"]:\n",
    "        print(\"Goodbye!\")\n",
    "        break\n",
    "    \n",
    "    if not user_input:\n",
    "        print(\"Please enter a goal.\")\n",
    "        continue\n",
    "    \n",
    "    if user_input.lower() == \"refine\" and last_prompt:\n",
    "        feedback = input(\"What would you like to change? \")\n",
    "        result = refine_prompt(last_prompt, feedback)\n",
    "    else:\n",
    "        result = generate_prompt(user_input)\n",
    "    \n",
    "    print(f\"\\n{result}\\n\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    # Extract the prompt for potential refinement\n",
    "    if \"```\" in result:\n",
    "        start = result.find(\"```\") + 3\n",
    "        end = result.find(\"```\", start)\n",
    "        if end > start:\n",
    "            last_prompt = result[start:end].strip()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}