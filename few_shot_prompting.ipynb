{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Few-Shot Prompting Example\n",
    "\n",
    "This notebook demonstrates **Few-Shot Prompting**, a technique that allows you to \"teach\" the AI a new task without any model training.\n",
    "\n",
    "**The Concept:**\n",
    "Most LLMs are \"Zero-Shot\" learners, meaning they can answer questions without examples. However, for specific formats, styles, or complex logic, they perform much better if you provide a few examples of **Input → Output** pairs in the prompt. This is called **In-Context Learning**.\n",
    "\n",
    "**Key Mechanics:**\n",
    "1.  **Examples**: We provide 3–5 high-quality examples of the task (e.g., \"Input: A, Output: B\").\n",
    "2.  **Pattern Recognition**: The model looks at these examples, infers the rule, and applies it to your new input.\n",
    "3.  **Result**: Better formatting, tone consistency, and accuracy for specialized tasks (like translating to \"Pirate English\" or extracting data to JSON)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install openai python-dotenv --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Setup and Authorization\n",
    "\n",
    "We start by importing the necessary libraries and loading your OpenAI API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from openai import OpenAI\nimport os\nfrom dotenv import load_dotenv\n\nload_dotenv()\n\napi_key = os.getenv(\"OPENAI_API_KEY\")\nif not api_key:\n    api_key = input(\"Paste your OpenAI API key: \").strip()\n\n# Model configuration - can be overridden via environment variable\nMODEL = os.getenv(\"OPENAI_MODEL\", \"gpt-4o-mini\")\n\nclient = OpenAI(api_key=api_key)\nprint(f\"OpenAI client ready! Using model: {MODEL}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Defining the \"Training\" Data\n",
    "\n",
    "In this step, we create the **Few-Shot Prompt**. Unlike a standard instruction (\"Translate this\"), we feed the model a mini-dataset of correct behaviors.\n",
    "\n",
    "You can select from several pre-written tasks below to see how the model adapts its behavior based *solely* on the examples provided in the string variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "TASKS = {\n    \"1\": \"Sentiment Analysis (positive/negative/neutral)\",\n    \"2\": \"Translate to Pirate English\",\n    \"3\": \"Extract Named Entities (Person, Org, Location)\",\n    \"4\": \"Correct Grammar & Make Professional\",\n    \"5\": \"Answer in JSON Format\",\n    \"6\": \"Custom (Write your own examples)\"\n}\n\n# Default sentiment analysis prompt (used for fallback)\nSENTIMENT_PROMPT = \"\"\"\nClassify the sentiment as positive, negative, or neutral.\n\nText: I love this product! It's amazing.\nSentiment: positive\n\nText: This is the worst experience ever.\nSentiment: negative\n\nText: It's okay, nothing special.\nSentiment: neutral\n\nText: The delivery was fast and the quality is good.\nSentiment: positive\n\nText:\"\"\"\n\nprint(\"Few-Shot Prompting Playground\")\nprint(\"Choose a task to see how examples guide the model:\")\nfor k, v in TASKS.items():\n    print(f\"  {k}. {v}\")\n\nchoice = input(\"\\nEnter number (1–6): \").strip()\n\nif choice == \"1\":\n    few_shot_prompt = SENTIMENT_PROMPT\n    print(\"Task: Sentiment Analysis\")\n\nelif choice == \"2\":\n    few_shot_prompt = \"\"\"\nTranslate the following to pirate speech:\n\nHello, how are you? → Ahoy matey, how be ye?\nThank you very much → Thank ye kindly, ye scurvy dog!\nWhere is the treasure? → Where be the booty buried?\nI'm hungry → Me belly be growlin' fer grub!\n\nNow translate:\"\"\"\n    print(\"Task: Pirate English Translator\")\n\nelif choice == \"3\":\n    few_shot_prompt = \"\"\"\nExtract named entities and label as PERSON, ORGANIZATION, or LOCATION.\n\nInput: Elon Musk founded SpaceX in California.\nOutput:\n- Elon Musk → PERSON\n- SpaceX → ORGANIZATION\n- California → LOCATION\n\nInput: Apple is releasing a new iPhone in New York next month.\nOutput:\n- Apple → ORGANIZATION\n- iPhone → PRODUCT\n- New York → LOCATION\n\nInput:\"\"\"\n    print(\"Task: Named Entity Recognition\")\n\nelif choice == \"4\":\n    few_shot_prompt = \"\"\"\nCorrect grammar and rewrite in professional business tone:\n\nhey wanna grab coffee later? → Hello, would you like to get coffee later this week?\ni think its gonna work good → I believe this solution will perform effectively.\nsorry im late traffic was bad → Apologies for the delay; I was caught in heavy traffic.\n\nRewrite:\"\"\"\n    print(\"Task: Grammar & Professional Tone\")\n\nelif choice == \"5\":\n    few_shot_prompt = \"\"\"\nAnswer in valid JSON format only:\n\nWhat is the capital of France? → {\"answer\": \"Paris\", \"country\": \"France\"}\nWho wrote Romeo and Juliet? → {\"answer\": \"William Shakespeare\", \"work\": \"Romeo and Juliet\", \"year\": 1597}\nWhat is 15 + 27? → {\"answer\": 42, \"operation\": \"addition\"}\n\nQuestion:\"\"\"\n    print(\"Task: Force JSON Output\")\n\nelif choice == \"6\":\n    print(\"Custom Few-Shot: Write 3–5 input/output examples below.\")\n    print(\"Example format:\\nText: hello world\\nOutput: HELLO WORLD\\n\\n\")\n    few_shot_prompt = input(\"Paste your full few-shot examples here:\\n\")\n    few_shot_prompt += \"\\nNow process this input:\\n\"\nelse:\n    print(\"Invalid choice. Defaulting to sentiment analysis.\")\n    choice = \"1\"\n    few_shot_prompt = SENTIMENT_PROMPT"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. The Execution Engine\n",
    "\n",
    "Now we run the model.\n",
    "\n",
    "**How it works:**\n",
    "1.  **Concatenation**: We take the `few_shot_prompt` (the examples) and append your new `user_input` to the end.\n",
    "2.  **Completion**: The model sees the pattern (Example 1, Example 2, Example 3, **New Input**) and naturally completes the pattern.\n",
    "3.  **Low Temperature**: We use a very low temperature (`0.1`) because we want the model to adhere strictly to the format of the examples, not to be creative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"\\nFew-Shot Engine Ready! Type 'quit' to exit.\\n\")\n\nwhile True:\n    user_input = input(\"Input: \")\n    if user_input.strip().lower() in [\"quit\", \"exit\", \"stop\"]:\n        print(\"\\nThanks for playing with few-shot!\")\n        break\n    \n    if not user_input.strip():\n        print(\"Please enter valid input.\")\n        continue\n\n    # Combine the examples with the new user input\n    full_prompt = few_shot_prompt + \" \" + user_input\n\n    try:\n        response = client.chat.completions.create(\n            model=MODEL,\n            messages=[\n                # We add a system message to reinforce that it should follow the pattern\n                {\"role\": \"system\", \"content\": \"You are an expert at following patterns from examples. Never explain, just output in the exact format shown.\"},\n                {\"role\": \"user\", \"content\": full_prompt}\n            ],\n            temperature=0.1,  # Low temp = high consistency\n            max_tokens=500\n        )\n\n        result = response.choices[0].message.content.strip()\n        print(f\"\\nOutput:\\n{result}\\n\\n\" + \"─\"*50)\n        \n    except Exception as e:\n        print(f\"\\nError: {e}\\n\")"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}