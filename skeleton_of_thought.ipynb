{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Skeleton-of-Thought (SoT) Prompting\n",
    "\n",
    "This notebook demonstrates **Skeleton-of-Thought (SoT)**, a technique designed to accelerate high-quality content generation and improve structure.\n",
    "\n",
    "**The Concept:**\n",
    "When humans write long essays, we usually outline first. **SoT** forces the LLM to do the same:\n",
    "1.  **Skeleton Stage**: The model generates a concise outline (the \"Skeleton\") of the answer.\n",
    "2.  **Point Expansion**: We treat each point in the outline as a separate sub-task and ask the model to expand on it.\n",
    "3.  **Combination**: We merge the expanded sections into a final document.\n",
    "\n",
    "**Key Mechanics:**\n",
    "* **Structure**: By defining the skeleton first, the final output is more coherent and less likely to ramble.\n",
    "* **Speed**: In production systems, the \"Point Expansion\" phase can be run in **parallel** (concurrent API calls), drastically reducing the time needed to generate long reports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install openai python-dotenv --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Setup and Authorization\n",
    "\n",
    "We start by importing the necessary libraries and loading your OpenAI API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from openai import OpenAI\nimport os\nimport time\nfrom dotenv import load_dotenv\n\nload_dotenv()\n\napi_key = os.getenv(\"OPENAI_API_KEY\")\nif not api_key:\n    api_key = input(\"Paste your OpenAI API key: \").strip()\n\n# Model configuration - can be overridden via environment variable\nMODEL = os.getenv(\"OPENAI_MODEL\", \"gpt-4o-mini\")\n\nclient = OpenAI(api_key=api_key)\nprint(f\"OpenAI client ready! Using model: {MODEL}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Stage 1: Generating the Skeleton\n",
    "\n",
    "In this step, we ask the model to create a high-level structure. We explicitly ask for a **numbered list** to make parsing easier later.\n",
    "\n",
    "**Note:** We use a strict prompt to ensure it *only* gives us the outline, not the full text yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def generate_skeleton(query):\n    print(f\"Creating skeleton for: '{query}'...\\n\")\n    \n    try:\n        response = client.chat.completions.create(\n            model=MODEL,\n            messages=[{\n                \"role\": \"user\", \n                \"content\": f\"\"\"\nYou are an expert outline writer.\nCreate a concise, detailed numbered skeleton outline (8â€“12 points) for answering this request:\n\nRequest: {query}\n\nReturn ONLY the numbered list. No introduction, no conclusion, no full text.\n\"\"\"\n            }],\n            temperature=0.3 # Low temp for a logical, standard structure\n        )\n        \n        skeleton_text = response.choices[0].message.content.strip()\n        print(f\"--- SKELETON ---\\n{skeleton_text}\\n----------------\")\n        \n        # Parse the skeleton into a list of points\n        # We assume valid points start with a digit (e.g., \"1. Introduction\")\n        points = [\n            line.strip() \n            for line in skeleton_text.split(\"\\n\") \n            if line.strip() and line.strip()[0].isdigit()\n        ]\n        \n        return points\n        \n    except Exception as e:\n        print(f\"Error generating skeleton: {e}\")\n        return []"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Stage 2: Parallel Expansion (The \"Flesh\")\n",
    "\n",
    "Now we iterate through the skeleton. For each point, we send a specific prompt to the model: *\"Write the content for this specific section.\"*\n",
    "\n",
    "**Why is this powerful?**\n",
    "* **Focus**: The model answers one specific sub-topic at a time, leading to more detailed and accurate content.\n",
    "* **Context**: We pass the original `query` along with the `point` so the model knows the overall context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def expand_points(points, original_query):\n    print(f\"\\nExpanding {len(points)} sections...\\n\")\n    full_document = []\n    \n    for i, point in enumerate(points, 1):\n        print(f\"  > Writing section {i}/{len(points)}: {point[:50]}...\", end=\"\\r\")\n        \n        try:\n            response = client.chat.completions.create(\n                model=MODEL,\n                messages=[{\n                    \"role\": \"user\", \n                    \"content\": f\"\"\"\nYou are writing one section of a larger document.\n\nTopic: {original_query}\nCurrent Section Goal: {point}\n\nWrite a detailed, comprehensive paragraph(s) for ONLY this section. \nDo not write an intro or conclusion for the whole document, just this part.\n\"\"\"\n                }],\n                temperature=0.7 # Higher temp for creative writing flow\n            )\n            \n            content = response.choices[0].message.content.strip()\n            \n            # Format: Header + Content\n            section_text = f\"## {point}\\n{content}\"\n            full_document.append(section_text)\n            \n        except Exception as e:\n            print(f\"\\n  Error expanding section {i}: {e}\")\n            full_document.append(f\"## {point}\\n[Error: Could not expand this section]\")\n        \n        # Brief pause to respect rate limits (optional)\n        time.sleep(0.2)\n        \n    print(f\"  Expansion complete!                        \")\n    return \"\\n\\n\".join(full_document)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Running the SoT Process\n",
    "\n",
    "Let's try it on a topic that usually requires a long, structured answer, like a blog post or a guide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_topic = input(\"Enter a topic (e.g., 'A guide to growing tomatoes' or 'The history of the internet'): \")\n",
    "\n",
    "if user_topic:\n",
    "    # 1. Get the Outline\n",
    "    skeleton_points = generate_skeleton(user_topic)\n",
    "    \n",
    "    if skeleton_points:\n",
    "        # 2. Fill in the Content\n",
    "        final_doc = expand_points(skeleton_points, user_topic)\n",
    "        \n",
    "        # 3. Display Result\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(f\"# {user_topic.upper()}\")\n",
    "        print(\"=\"*60)\n",
    "        print(final_doc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}